{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nopalraihan/Data-Porto/blob/claude/document-automation-excel-pdf-QC9W8/document_automation/Document_Automation_PLN_Crosscheck.ipynb)\n\n# PLN Document Automation & Crosscheck System\n\n**ML-Powered document verification pipeline**\n\nThis notebook provides:\n1. **PLN Document Crosscheck** — Read PDF doc → compare against Excel template → verify or log mismatches\n2. **General Document Automation** — Read any CSV/Excel/PDF → process → export to formatted Excel & PDF reports\n3. **ML Analysis** — TF-IDF text similarity, Anomaly Detection, Random Forest confidence scoring\n\n---\n\n### How to use\n1. Click the **\"Open in Colab\"** badge above to launch in Google Colab\n2. Run **Section 1** to install dependencies & clone the repo\n3. Run **Section 2** for the PLN Crosscheck demo (or upload your own files)\n4. Run **Section 3** for general document automation\n\n> Works on **Google Colab** and any Jupyter environment."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pandas openpyxl fpdf2 PyPDF2 scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (skip if running locally)\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/nopalraihan/Data-Porto.git\"\n",
    "BRANCH = \"claude/document-automation-excel-pdf-QC9W8\"\n",
    "PROJECT_DIR = \"/content/Data-Porto\"  # Colab path\n",
    "\n",
    "# Use local path if not on Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    ON_COLAB = True\n",
    "except ImportError:\n",
    "    ON_COLAB = False\n",
    "    PROJECT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    # Walk up to find Data-Porto root\n",
    "    while PROJECT_DIR != \"/\" and not os.path.isfile(os.path.join(PROJECT_DIR, \"requirements.txt\")):\n",
    "        PROJECT_DIR = os.path.dirname(PROJECT_DIR)\n",
    "\n",
    "if ON_COLAB:\n",
    "    if os.path.isdir(PROJECT_DIR):\n",
    "        print(f\"Repo already exists at {PROJECT_DIR}\")\n",
    "        !cd {PROJECT_DIR} && git pull origin {BRANCH}\n",
    "    else:\n",
    "        !git clone -b {BRANCH} {REPO_URL} {PROJECT_DIR}\n",
    "\n",
    "# Add project root to Python path\n",
    "import sys\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "print(f\"Project directory: {PROJECT_DIR}\")\n",
    "print(f\"Running on: {'Google Colab' if ON_COLAB else 'Local Jupyter'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports work\n",
    "from document_automation.readers.document_reader import DocumentReader\n",
    "from document_automation.writers.excel_writer import ExcelWriter\n",
    "from document_automation.writers.pdf_writer import PDFWriter\n",
    "from document_automation.utils.data_processor import DataProcessor\n",
    "from document_automation.pipeline import Pipeline\n",
    "from document_automation.crosscheck.pln_extractor import PLNExtractor\n",
    "from document_automation.crosscheck.crosscheck_engine import CrosscheckEngine\n",
    "from document_automation.crosscheck.report_generator import ReportGenerator\n",
    "from document_automation.crosscheck.create_template import create_template\n",
    "from document_automation.ml.text_similarity import TextSimilarity\n",
    "from document_automation.ml.anomaly_detector import AnomalyDetector\n",
    "from document_automation.ml.confidence_scorer import ConfidenceScorer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. PLN Document Crosscheck\n",
    "\n",
    "### Flow:\n",
    "```\n",
    "PDF Document (from field)     Excel Template (from HO PLN)\n",
    "        |                              |\n",
    "        v                              v\n",
    "  PLNExtractor                   pd.read_excel()\n",
    "  (extract fields)              (load expected data)\n",
    "        |                              |\n",
    "        +----------+   +---------------+\n",
    "                   v   v\n",
    "            CrosscheckEngine + ML Models\n",
    "                     |\n",
    "          +----------+----------+\n",
    "          v          v          v\n",
    "      ALL MATCH   MISMATCH   MISSING\n",
    "      VERIFIED    error log  warning\n",
    "                     |\n",
    "                     v\n",
    "              ReportGenerator\n",
    "         (Excel + PDF output reports)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Run Demo (with sample data)\n",
    "This demo simulates a PLN document with **2 intentional mismatches** to show the full verification flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, \"document_automation\", \"output\")\n",
    "SAMPLE_DIR = os.path.join(PROJECT_DIR, \"document_automation\", \"sample_data\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
    "\n",
    "# Step 1: Create the Excel template\n",
    "template_path = create_template(os.path.join(SAMPLE_DIR, \"PLN_Crosscheck_Template.xlsx\"))\n",
    "print(f\"Template created: {template_path}\")\n",
    "\n",
    "# Preview the template\n",
    "df_template = pd.read_excel(template_path, sheet_name=\"Data Pelanggan\", header=3)\n",
    "df_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Simulate PDF extraction\n",
    "# (In real use, PLNExtractor reads this from your actual PDF)\n",
    "simulated_pdf_fields = {\n",
    "    \"id_pelanggan\": \"532100012345\",\n",
    "    \"nama_pelanggan\": \"SUHARTO\",\n",
    "    \"alamat\": \"JL. PENGGILINGAN ELOK NO.23 RT005/RW012, PENGGILINGAN, CAKUNG, JAKARTA TIMUR\",\n",
    "    \"tarif_daya\": \"R1/1300 VA\",\n",
    "    \"nomor_meter\": \"JTX476\",\n",
    "    \"nomor_kwh\": \"85201234\",\n",
    "    \"periode\": \"Januari 2026\",\n",
    "    \"stand_meter_awal\": \"15230\",\n",
    "    \"stand_meter_akhir\": \"15510\",     # << MISMATCH: Excel says 15480\n",
    "    \"pemakaian_kwh\": \"280\",            # << MISMATCH: Excel says 250\n",
    "    \"biaya_listrik\": \"352500\",\n",
    "}\n",
    "\n",
    "print(\"Simulated PDF fields:\")\n",
    "for k, v in simulated_pdf_fields.items():\n",
    "    print(f\"  {k:25s} = {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run the ML-enhanced crosscheck\n",
    "engine = CrosscheckEngine(simulated_pdf_fields, df_template, use_ml=True)\n",
    "result = engine.run()\n",
    "\n",
    "# Display results as a table\n",
    "results_df = pd.DataFrame(result[\"results\"])\n",
    "display_cols = [\"field_name\", \"pdf_value\", \"excel_value\", \"match_status\", \"notes\"]\n",
    "if \"similarity_score\" in results_df.columns:\n",
    "    display_cols.append(\"similarity_score\")\n",
    "\n",
    "print(\"\\n=== CROSSCHECK RESULTS ===\")\n",
    "results_df[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: View summary & ML analysis\n",
    "summary = result[\"summary\"]\n",
    "pct = summary[\"match_percentage\"]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "if pct == 100:\n",
    "    print(f\"VERDICT: VERIFIED - All {summary['total_fields_checked']} fields match!\")\n",
    "else:\n",
    "    print(f\"VERDICT: MISMATCH DETECTED\")\n",
    "    print(f\"  {summary['total_match']}/{summary['total_fields_checked']} match ({pct}%)\")\n",
    "    print(f\"  {summary['total_mismatch']} MISMATCHES | {summary['total_missing']} MISSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ML Confidence\n",
    "if \"ml_confidence\" in result:\n",
    "    conf = result[\"ml_confidence\"]\n",
    "    print(f\"\\nML Confidence Score: {conf['confidence_score']}%\")\n",
    "    print(f\"Prediction: {conf['prediction']}\")\n",
    "    print(f\"Risk Level: {conf['risk_level']}\")\n",
    "\n",
    "# Text Similarity\n",
    "if \"ml_similarity\" in result:\n",
    "    print(f\"\\nText Similarity:\")\n",
    "    for field, sim in result[\"ml_similarity\"].items():\n",
    "        print(f\"  {field}: {sim['score']:.4f} ({sim['classification']})\")\n",
    "\n",
    "# Anomalies\n",
    "if \"ml_anomalies\" in result:\n",
    "    flags = result[\"ml_anomalies\"]\n",
    "    if flags:\n",
    "        print(f\"\\nAnomalies ({len(flags)}):\")\n",
    "        for f in flags:\n",
    "            print(f\"  [{f['severity']}] {f['field']}: {f['message']}\")\n",
    "    else:\n",
    "        print(\"\\nNo anomalies detected.\")\n",
    "\n",
    "# Error log\n",
    "mismatches = [r for r in result[\"results\"] if r[\"match_status\"] == \"MISMATCH\"]\n",
    "if mismatches:\n",
    "    print(f\"\\nERROR LOG ({len(mismatches)} mismatches):\")\n",
    "    for i, r in enumerate(mismatches, 1):\n",
    "        print(f\"  #{i} {r['field_name']}\")\n",
    "        print(f\"     PDF:   {r.get('pdf_value', 'N/A')}\")\n",
    "        print(f\"     Excel: {r.get('excel_value', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate Excel & PDF reports\n",
    "reporter = ReportGenerator(\n",
    "    result,\n",
    "    {\"file_name\": \"23.Dok PLN PENGGILINGANELOK_JTX476.pdf\", \"page_count\": 2},\n",
    "    OUTPUT_DIR,\n",
    ")\n",
    "outputs = reporter.generate_all()\n",
    "\n",
    "print(f\"Excel report: {outputs['excel']}\")\n",
    "print(f\"PDF report:   {outputs['pdf']}\")\n",
    "\n",
    "# Download files on Colab\n",
    "if ON_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"\\nDownloading reports...\")\n",
    "    files.download(outputs[\"excel\"])\n",
    "    files.download(outputs[\"pdf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Upload Your Own Files\n",
    "Upload your actual PLN PDF and Excel template to crosscheck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files (Colab only - skip on local Jupyter)\n",
    "pdf_path = None\n",
    "excel_path = None\n",
    "\n",
    "if ON_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"Upload your PLN PDF document:\")\n",
    "    uploaded = files.upload()\n",
    "    for name in uploaded:\n",
    "        if name.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(\"/content\", name)\n",
    "            with open(pdf_path, \"wb\") as f:\n",
    "                f.write(uploaded[name])\n",
    "            print(f\"  PDF saved: {pdf_path}\")\n",
    "\n",
    "    print(\"\\nUpload your Excel template:\")\n",
    "    uploaded = files.upload()\n",
    "    for name in uploaded:\n",
    "        if name.lower().endswith((\".xlsx\", \".xls\")):\n",
    "            excel_path = os.path.join(\"/content\", name)\n",
    "            with open(excel_path, \"wb\") as f:\n",
    "                f.write(uploaded[name])\n",
    "            print(f\"  Excel saved: {excel_path}\")\n",
    "else:\n",
    "    # For local Jupyter: set paths manually\n",
    "    # pdf_path = \"/path/to/your/PLN_document.pdf\"\n",
    "    # excel_path = \"/path/to/your/PLN_Crosscheck_Template.xlsx\"\n",
    "    print(\"Local mode: Set pdf_path and excel_path manually in the cell above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run crosscheck on your uploaded files\n",
    "if pdf_path and excel_path:\n",
    "    # Extract from PDF\n",
    "    print(\"Extracting fields from PDF...\")\n",
    "    extractor = PLNExtractor(pdf_path)\n",
    "    extraction = extractor.extract()\n",
    "    pdf_fields = {k: v[\"value\"] for k, v in extraction[\"fields\"].items()}\n",
    "\n",
    "    print(f\"Found {len(pdf_fields)} fields:\")\n",
    "    for k, v in pdf_fields.items():\n",
    "        print(f\"  {k:25s} = {v}\")\n",
    "\n",
    "    # Load template\n",
    "    df = pd.read_excel(excel_path, sheet_name=\"Data Pelanggan\", header=3)\n",
    "    print(f\"\\nTemplate rows: {len(df)}\")\n",
    "\n",
    "    # Crosscheck\n",
    "    print(\"\\nRunning crosscheck...\")\n",
    "    engine = CrosscheckEngine(pdf_fields, df, use_ml=True)\n",
    "    result = engine.run()\n",
    "\n",
    "    # Show results table\n",
    "    results_df = pd.DataFrame(result[\"results\"])\n",
    "    display(results_df[[\"field_name\", \"pdf_value\", \"excel_value\", \"match_status\", \"notes\"]])\n",
    "\n",
    "    # Verdict\n",
    "    s = result[\"summary\"]\n",
    "    print(f\"\\nMatch: {s['total_match']}/{s['total_fields_checked']} ({s['match_percentage']}%)\")\n",
    "    if \"ml_confidence\" in result:\n",
    "        print(f\"ML Confidence: {result['ml_confidence']['confidence_score']}% ({result['ml_confidence']['prediction']})\")\n",
    "\n",
    "    # Generate reports\n",
    "    reporter = ReportGenerator(result, extraction[\"metadata\"], OUTPUT_DIR)\n",
    "    outputs = reporter.generate_all()\n",
    "    print(f\"\\nExcel: {outputs['excel']}\")\n",
    "    print(f\"PDF:   {outputs['pdf']}\")\n",
    "\n",
    "    if ON_COLAB:\n",
    "        files.download(outputs[\"excel\"])\n",
    "        files.download(outputs[\"pdf\"])\n",
    "else:\n",
    "    print(\"No files uploaded. Run the upload cell above first, or use the demo in Section 2a.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. General Document Automation\n",
    "\n",
    "Read any **CSV**, **Excel**, or **PDF** file → process → export to formatted **Excel** and **PDF** reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Using the sample employee dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline on sample CSV\n",
    "sample_csv = os.path.join(PROJECT_DIR, \"document_automation\", \"sample_data\", \"employees.csv\")\n",
    "\n",
    "pipeline = Pipeline(sample_csv, output_dir=OUTPUT_DIR)\n",
    "result = pipeline.run(\n",
    "    title=\"Employee Analytics Report\",\n",
    "    filters=[{\"column\": \"salary\", \"operator\": \">=\", \"value\": 60000}],\n",
    "    group_by={\"group_col\": \"department\", \"agg_col\": \"salary\", \"agg_func\": \"mean\"},\n",
    "    top_n={\"column\": \"salary\", \"n\": 10, \"ascending\": False},\n",
    ")\n",
    "\n",
    "print(f\"Excel: {result['excel']}\")\n",
    "print(f\"PDF:   {result['pdf']}\")\n",
    "print(f\"Summary: {result['summary']}\")\n",
    "\n",
    "if ON_COLAB:\n",
    "    files.download(result[\"excel\"])\n",
    "    files.download(result[\"pdf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Upload your own document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload any CSV, Excel, or PDF file\n",
    "doc_path = None\n",
    "\n",
    "if ON_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"Upload a CSV, Excel, or PDF file:\")\n",
    "    uploaded = files.upload()\n",
    "    for name in uploaded:\n",
    "        doc_path = os.path.join(\"/content\", name)\n",
    "        with open(doc_path, \"wb\") as f:\n",
    "            f.write(uploaded[name])\n",
    "        print(f\"Saved: {doc_path}\")\n",
    "else:\n",
    "    # doc_path = \"/path/to/your/file.csv\"\n",
    "    print(\"Local mode: Set doc_path manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the uploaded document\n",
    "if doc_path:\n",
    "    # Preview\n",
    "    reader = DocumentReader(doc_path)\n",
    "    print(reader.summary())\n",
    "    print()\n",
    "\n",
    "    # Run pipeline\n",
    "    pipeline = Pipeline(doc_path, output_dir=OUTPUT_DIR)\n",
    "    result = pipeline.run(title=\"Document Report\")\n",
    "\n",
    "    for key, val in result.items():\n",
    "        print(f\"{key}: {val}\")\n",
    "\n",
    "    if ON_COLAB:\n",
    "        if \"excel\" in result:\n",
    "            files.download(result[\"excel\"])\n",
    "        if \"pdf\" in result:\n",
    "            files.download(result[\"pdf\"])\n",
    "else:\n",
    "    print(\"No file uploaded. Run the upload cell above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ML Models - Standalone Usage\n",
    "\n",
    "Use the ML components independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Text Similarity\n",
    "sim = TextSimilarity()\n",
    "\n",
    "test_pairs = [\n",
    "    (\"JL. PENGGILINGAN ELOK NO.23\", \"JALAN PENGGILINGAN ELOK NOMOR 23\"),\n",
    "    (\"SUHARTO\", \"SUHARTO\"),\n",
    "    (\"DEWI SARTIKA\", \"DWI SARTIKA\"),\n",
    "    (\"Jl. Merdeka No.10 Jakarta\", \"Jalan Merdeka Nomor 10, Jakarta Pusat\"),\n",
    "    (\"BAMBANG WIJAYA\", \"AHMAD FAUZI\"),\n",
    "]\n",
    "\n",
    "print(\"TF-IDF Cosine Similarity Results:\")\n",
    "print(\"-\" * 80)\n",
    "for a, b in test_pairs:\n",
    "    score = sim.score(a, b)\n",
    "    cls = sim.classify_match(score)\n",
    "    print(f\"  {score:.4f} [{cls:10s}]  '{a}'  vs  '{b}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Detection\n",
    "detector = AnomalyDetector()\n",
    "\n",
    "# Normal case\n",
    "normal = {\n",
    "    \"tarif_daya\": \"R1/1300 VA\",\n",
    "    \"stand_meter_awal\": \"15230\",\n",
    "    \"stand_meter_akhir\": \"15480\",\n",
    "    \"pemakaian_kwh\": \"250\",\n",
    "    \"biaya_listrik\": \"361000\",\n",
    "}\n",
    "\n",
    "# Suspicious case\n",
    "suspicious = {\n",
    "    \"tarif_daya\": \"R1/900 VA\",\n",
    "    \"stand_meter_awal\": \"10000\",\n",
    "    \"stand_meter_akhir\": \"9500\",   # meter went backwards!\n",
    "    \"pemakaian_kwh\": \"5000\",        # impossibly high\n",
    "    \"biaya_listrik\": \"100000\",      # rate doesn't match\n",
    "}\n",
    "\n",
    "print(\"Normal case:\")\n",
    "flags = detector.check_single(normal)\n",
    "print(f\"  {len(flags)} flags\" if flags else \"  No anomalies\")\n",
    "\n",
    "print(\"\\nSuspicious case:\")\n",
    "flags = detector.check_single(suspicious)\n",
    "for f in flags:\n",
    "    print(f\"  [{f['severity']:8s}] {f['field']}: {f['message']}\")\n",
    "    print(f\"           Expected: {f['expected']} | Actual: {f['actual']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Confidence Scorer\n",
    "scorer = ConfidenceScorer()\n",
    "train_info = scorer.train()\n",
    "print(\"Model trained:\")\n",
    "print(f\"  Accuracy: {train_info['train_accuracy']:.2%}\")\n",
    "print(f\"  Samples: {train_info['samples']}\")\n",
    "print(f\"\\nFeature importances:\")\n",
    "for feat, imp in sorted(train_info[\"feature_importances\"].items(), key=lambda x: -x[1]):\n",
    "    bar = '#' * int(imp * 50)\n",
    "    print(f\"  {feat:25s} {imp:.4f}  {bar}\")\n",
    "\n",
    "# Score a valid document\n",
    "print(\"\\n--- Valid document ---\")\n",
    "r = scorer.score({\"match_ratio\": 1.0, \"name_similarity\": 0.98, \"address_similarity\": 0.95,\n",
    "                  \"meter_deviation\": 0.0, \"billing_deviation\": 0.0, \"anomaly_count\": 0, \"missing_fields\": 0})\n",
    "print(f\"  Confidence: {r['confidence_score']}% | {r['prediction']} | Risk: {r['risk_level']}\")\n",
    "\n",
    "# Score a suspicious document\n",
    "print(\"\\n--- Suspicious document ---\")\n",
    "r = scorer.score({\"match_ratio\": 0.5, \"name_similarity\": 0.4, \"address_similarity\": 0.3,\n",
    "                  \"meter_deviation\": 0.3, \"billing_deviation\": 0.4, \"anomaly_count\": 3, \"missing_fields\": 2})\n",
    "print(f\"  Confidence: {r['confidence_score']}% | {r['prediction']} | Risk: {r['risk_level']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Save to Google Drive (Optional)\n",
    "\n",
    "Mount Google Drive and copy output reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # Copy all output reports to Drive\n",
    "    import shutil\n",
    "    drive_output = \"/content/drive/MyDrive/PLN_Crosscheck_Reports\"\n",
    "    os.makedirs(drive_output, exist_ok=True)\n",
    "\n",
    "    for f in os.listdir(OUTPUT_DIR):\n",
    "        if f.endswith((\".xlsx\", \".pdf\")):\n",
    "            src = os.path.join(OUTPUT_DIR, f)\n",
    "            dst = os.path.join(drive_output, f)\n",
    "            shutil.copy2(src, dst)\n",
    "            print(f\"Copied: {f}\")\n",
    "\n",
    "    print(f\"\\nAll reports saved to: {drive_output}\")\n",
    "else:\n",
    "    print(f\"Reports are in: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}